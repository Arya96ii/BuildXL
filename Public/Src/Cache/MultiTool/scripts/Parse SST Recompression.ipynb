{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = pathlib.Path('D:\\checkpoints')\n",
    "\n",
    "def attempt_convert(v):\n",
    "    try:\n",
    "        try:\n",
    "            return int(v)\n",
    "        except:\n",
    "            return float(v)\n",
    "    except:\n",
    "        return v\n",
    "\n",
    "df = []\n",
    "extract_block_size_regex = re.compile(r'Block Size: (?P<BlockSize>[0-9]+)')\n",
    "extract_compression_regex = re.compile(r'Compression: (?P<CompressionType>[^\\s]+)\\s*Compression level: (?P<CompressionLevel>[0-9]+)\\s*Size:\\s*(?P<CompressedSize>[0-9]+)\\s*Blocks:\\s*(?P<NumBlocks>[0-9]+)\\s*Time Taken:\\s*(?P<TimeTakenMicros>[0-9]+)\\s*microsecs\\s*Compressed:\\s*(?P<Compressed>[0-9]+)\\s*\\(\\s*(?P<CompressedPct>.*?)%\\)\\s*Not compressed \\(ratio\\):\\s*(?P<NotCompressedRatio>[0-9]+)\\s*\\(\\s*(?P<NotCompressedRatioPct>.*?)%\\)\\s*Not compressed \\(abort\\):\\s*(?P<NotCompressedAbort>[0-9]+)\\s*\\(\\s*(?P<NotCompressedAbortPct>.*?)%\\)')\n",
    "for checkpoint in os.listdir(INPUT_PATH):\n",
    "    checkpoint_path = INPUT_PATH / checkpoint\n",
    "    for sst in os.listdir(checkpoint_path):\n",
    "        sst_path = checkpoint_path / sst\n",
    "        if not sst_path.match('*.compression*.txt'):\n",
    "            continue\n",
    "        \n",
    "        contents = sst_path.read_text()\n",
    "        if 'Not able to read table properties' in contents:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            block_size = int(extract_block_size_regex.search(contents).group('BlockSize'))\n",
    "            checkpoint = checkpoint_path.stem\n",
    "            for algorithm in extract_compression_regex.finditer(contents):\n",
    "                entry = {k: attempt_convert(v) for k, v in algorithm.groupdict().items()}\n",
    "                entry['BlockSize'] = block_size\n",
    "                entry['Path'] = str(sst_path)\n",
    "                entry['Checkpoint'] = checkpoint\n",
    "                df.append(entry)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(contents)\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Sanitize compression algorithm names\n",
    "def rename_compression_types(compression_type):\n",
    "    renamer = {\n",
    "        'kNoCompression': 'uncompressed',\n",
    "        'kSnappyCompression': 'snappy',\n",
    "        'kZlibCompression': 'zlib',\n",
    "        'kLZ4Compression': 'lz4',\n",
    "        'kLZ4HCCompression': 'lz4hc',\n",
    "        'kZSTD': 'zstd'\n",
    "    }\n",
    "    return renamer[compression_type]\n",
    "\n",
    "df['CompressionType'] = df['CompressionType'].apply(rename_compression_types)\n",
    "\n",
    "# Compute compression rate\n",
    "uncompressed = df[df['CompressionType'] == 'uncompressed'][['Path', 'CompressedSize']].drop_duplicates()\n",
    "uncompressed.rename(columns={'CompressedSize': 'UncompressedSize'}, inplace=True)\n",
    "df = df.merge(uncompressed)\n",
    "del uncompressed\n",
    "\n",
    "df['CompressionRate'] = (1.0 - df['CompressedSize']/df['UncompressedSize'])\n",
    "\n",
    "# Filter out uncompressed, they are useless\n",
    "df = df[df['CompressionType'] != 'uncompressed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = df.groupby(['Checkpoint', 'CompressionType', 'BlockSize']).sum()[['CompressedSize', 'UncompressedSize']]\n",
    "cf['CompressionRate'] = cf['CompressedSize']/cf['UncompressedSize']\n",
    "snappySizes = []\n",
    "for idx, data in cf.iterrows():\n",
    "    snappySizes.append(cf.loc[(idx[0], 'snappy', idx[2])]['CompressedSize'])\n",
    "cf['BaselineCompressedSize'] = snappySizes\n",
    "cf['BaselineCompressionRate'] = cf['BaselineCompressedSize'] / cf['UncompressedSize']\n",
    "# A smaller compression rate means a lower size\n",
    "cf['BaselineCompressionImprovement'] = cf['BaselineCompressionRate'] - cf['CompressionRate']\n",
    "del snappySizes\n",
    "del cf['BaselineCompressedSize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.sort_values(by=['BaselineCompressionImprovement'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
